{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f458ad70-bc42-4a87-aca7-403de43886bb",
   "metadata": {},
   "source": [
    "# Chapter 19 - Reinforcement Learning for Decision Making in Complex Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a948af74-228d-4198-ac3d-7eb77fec22b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8195156f-3c21-469f-8917-7cade17e9b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87cd83af-4d36-4ea4-a4c2-9d5e78a856b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01737694, -0.01369213,  0.02329976,  0.01050149], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9cd636d-f454-4cdf-97e3-22fa39c099ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.01765078, -0.20914035,  0.02350979,  0.31044376], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(action=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbcc25ae-68fc-40a6-b8a9-fba55a2dabef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.02183359, -0.0143611 ,  0.02971867,  0.02526686], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(action=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d357ef-9be6-4bff-bdb5-5f623d5d5323",
   "metadata": {},
   "source": [
    "# Implementing the grid world environment in OpenAI Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "936a8a6b-ef41-4064-bce4-9ae07ec20ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 22, 15, 10]\n",
      "Action   0 3  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   0 3  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   0 0  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   0 3  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   6 2  ->  (6, 0.0, False, {'prob': 1.0})\n",
      "Action   0 0  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   1 1  ->  (1, 0.0, False, {'prob': 1.0})\n",
      "Action   0 3  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   1 1  ->  (1, 0.0, False, {'prob': 1.0})\n",
      "Action   0 3  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   0 0  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   1 1  ->  (1, 0.0, False, {'prob': 1.0})\n",
      "Action   2 1  ->  (2, 0.0, False, {'prob': 1.0})\n",
      "Action   2 0  ->  (2, 0.0, False, {'prob': 1.0})\n",
      "Action   1 3  ->  (1, 0.0, False, {'prob': 1.0})\n",
      "Action   2 1  ->  (2, 0.0, False, {'prob': 1.0})\n",
      "Action   1 3  ->  (1, 0.0, False, {'prob': 1.0})\n",
      "Action   1 0  ->  (1, 0.0, False, {'prob': 1.0})\n",
      "Action   0 3  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   1 1  ->  (1, 0.0, False, {'prob': 1.0})\n",
      "Action   2 1  ->  (2, 0.0, False, {'prob': 1.0})\n",
      "Action   2 0  ->  (2, 0.0, False, {'prob': 1.0})\n",
      "Action   1 3  ->  (1, 0.0, False, {'prob': 1.0})\n",
      "Action   1 0  ->  (1, 0.0, False, {'prob': 1.0})\n",
      "Action   0 3  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   0 0  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   6 2  ->  (6, 0.0, False, {'prob': 1.0})\n",
      "Action   0 0  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   1 1  ->  (1, 0.0, False, {'prob': 1.0})\n",
      "Action   0 3  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   0 3  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   1 1  ->  (1, 0.0, False, {'prob': 1.0})\n",
      "Action   0 3  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   6 2  ->  (6, 0.0, False, {'prob': 1.0})\n",
      "Action   0 0  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   6 2  ->  (6, 0.0, False, {'prob': 1.0})\n",
      "Action   7 1  ->  (7, 0.0, False, {'prob': 1.0})\n",
      "Action   1 0  ->  (1, 0.0, False, {'prob': 1.0})\n",
      "Action   0 3  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   0 3  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   0 3  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   0 0  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   0 0  ->  (0, 0.0, False, {'prob': 1.0})\n",
      "Action   6 2  ->  (6, 0.0, False, {'prob': 1.0})\n",
      "Action   7 1  ->  (7, 0.0, False, {'prob': 1.0})\n",
      "Action   8 1  ->  (8, 0.0, False, {'prob': 1.0})\n",
      "Action   14 2  ->  (14, 0.0, False, {'prob': 1.0})\n",
      "Action   20 2  ->  (20, 0.0, False, {'prob': 1.0})\n",
      "Action   26 2  ->  (26, 0.0, False, {'prob': 1.0})\n",
      "Action   25 3  ->  (25, 0.0, False, {'prob': 1.0})\n",
      "Action   19 0  ->  (19, 0.0, False, {'prob': 1.0})\n",
      "Action   20 1  ->  (20, 0.0, False, {'prob': 1.0})\n",
      "Action   19 3  ->  (19, 0.0, False, {'prob': 1.0})\n",
      "Action   25 2  ->  (25, 0.0, False, {'prob': 1.0})\n",
      "Action   25 2  ->  (25, 0.0, False, {'prob': 1.0})\n",
      "Action   24 3  ->  (24, 0.0, False, {'prob': 1.0})\n",
      "Action   25 1  ->  (25, 0.0, False, {'prob': 1.0})\n",
      "Action   24 3  ->  (24, 0.0, False, {'prob': 1.0})\n",
      "Action   18 0  ->  (18, 0.0, False, {'prob': 1.0})\n",
      "Action   19 1  ->  (19, 0.0, False, {'prob': 1.0})\n",
      "Action   20 1  ->  (20, 0.0, False, {'prob': 1.0})\n",
      "Action   14 0  ->  (14, 0.0, False, {'prob': 1.0})\n",
      "Action   13 3  ->  (13, 0.0, False, {'prob': 1.0})\n",
      "Action   14 1  ->  (14, 0.0, False, {'prob': 1.0})\n",
      "Action   8 0  ->  (8, 0.0, False, {'prob': 1.0})\n",
      "Action   9 1  ->  (9, 0.0, False, {'prob': 1.0})\n",
      "Action   10 1  ->  (10, -1.0, False, {'prob': 1.0})\n",
      "Action   10 3  ->  (10, 0.0, True, {'prob': 1.0})\n"
     ]
    }
   ],
   "source": [
    "## Script: gridworld_env.py\n",
    "import numpy as np \n",
    "from gym.envs.toy_text import discrete\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from gym.envs.classic_control import rendering\n",
    "\n",
    "CELL_SIZE = 100\n",
    "MARGIN = 10\n",
    "\n",
    "\n",
    "def get_coords(row, col, loc='center'):\n",
    "    xc = (col + 1.5) * CELL_SIZE\n",
    "    yc = (row + 1.5) * CELL_SIZE\n",
    "    if loc == 'center':\n",
    "        return xc, yc\n",
    "    elif loc == 'interior_corners':\n",
    "        half_size = CELL_SIZE // - MARGIN\n",
    "        xl, xr = xc - half_size, xc + half_size\n",
    "        yt, yb = xc - half_size, xc + half_size\n",
    "        return [(xl, yt), (xr, yt), (xr, yb), (xl, yb)]\n",
    "    elif loc == 'interior_triangle':\n",
    "        x1, y1 = xc, yc + CELL_SIZE // 3\n",
    "        x2, y2 = xc + CELL_SIZE // 3, yc - CELL_SIZE // 3\n",
    "        x3, y3 = xc - CELL_SIZE // 3, yc - CELL_SIZE // 3\n",
    "        return [(x1, y1), (x2, y2), (x3, y3)]\n",
    "    \n",
    "    \n",
    "def draw_object(coords_list):\n",
    "    if len(coords_list) == 1: # -> circle\n",
    "        obj = rendering.make_circle(int(0.45 * CELL_SIZE))\n",
    "        obj_transform = rendering.Transform()\n",
    "        obj.add_attr(obj_transform)\n",
    "        obj_transform.set_translation(*coords_list[0])\n",
    "        obj.set_color(0.2, 0.2, 0.2) # -> balck\n",
    "    elif len(coords_list) == 3: # -> triangle\n",
    "        obj = rendering.FilledPolygon(coords_list)\n",
    "        obj.set_color(0.9, 0.6, 0.2) # -> yellow\n",
    "    elif len(coords_list) > 3: # -> polygon\n",
    "        obj = rendering.FilledPolygon(coords_list)\n",
    "        obj.set_color(0.4, 0.4, 0.8) # -> blue\n",
    "    return obj\n",
    "\n",
    "\n",
    "class GridWorldENV(discrete.DiscreteEnv):\n",
    "    def __init__(self, num_rows=4, num_cols=6, delay=0.05):\n",
    "        self.num_rows = num_rows\n",
    "        self.num_cols = num_cols\n",
    "        self.delay = delay\n",
    "        move_up = lambda row, col: (max(row-1, 0), col)\n",
    "        move_down = lambda row, col: (min(row+1, num_rows-1), col)\n",
    "        move_left = lambda row, col: (row, max(col-1, 0))\n",
    "        move_right = lambda row, col: (row, min(col+1, num_cols-1))\n",
    "        self.action_defs={0: move_up, 1: move_right,\n",
    "                          2: move_down, 3: move_left}\n",
    "        ## Number of states/actions\n",
    "        nS = num_cols * num_rows\n",
    "        nA = len(self.action_defs)\n",
    "        self.grid2state_dict={(s // num_cols, s%num_cols): s for s in range(nS)}\n",
    "        self.state2grid_dict={s: (s // num_cols, s%num_cols) for s in range(nS)}\n",
    "        \n",
    "        ## Gold state\n",
    "        gold_cell = (num_rows // 2, num_cols - 2)\n",
    "        \n",
    "        ## Trap states\n",
    "        trap_cells = [((gold_cell[0] + 1), gold_cell[1]),\n",
    "                       (gold_cell[0], gold_cell[1] - 1),\n",
    "                       ((gold_cell[0] - 1), gold_cell[1])]\n",
    "        gold_state = self.grid2state_dict[gold_cell]\n",
    "        trap_states = [self.grid2state_dict[(r, c)] for (r, c) in trap_cells]\n",
    "        self.terminal_states = [gold_state] + trap_states\n",
    "        print(self.terminal_states)\n",
    "        ## Build the transition probability\n",
    "        P = defaultdict(dict)\n",
    "        for s in range(nS):\n",
    "            row, col = self.state2grid_dict[s]\n",
    "            P[s] = defaultdict(list)\n",
    "            for a in range(nA):\n",
    "                action = self.action_defs[a]\n",
    "                next_s = self.grid2state_dict[action(row, col)]\n",
    "                \n",
    "                ## Terminal state\n",
    "                if self.is_terminal(next_s):\n",
    "                    r = (1.0 if next_s == self.terminal_states[0] else -1.0)\n",
    "                else:\n",
    "                    r = 0.0\n",
    "                if self.is_terminal(s):\n",
    "                    done = True\n",
    "                    next_s = s\n",
    "                else:\n",
    "                    done = False\n",
    "                P[s][a] = [(1.0, next_s, r, done)]\n",
    "        ## Initial state distribution\n",
    "        isd = np.zeros(nS)\n",
    "        isd[0]\n",
    "        super().__init__(nS, nA, P, isd)\n",
    "        self.viewer = None\n",
    "        self._build_display(gold_cell, trap_cells)\n",
    "        \n",
    "    def is_terminal(self, state):\n",
    "        return state in self.terminal_states\n",
    "    \n",
    "    def _build_display(self, gold_cell, trap_cells):\n",
    "        screen_width = (self.num_cols + 2) * CELL_SIZE\n",
    "        screen_height = (self.num_rows + 2) * CELL_SIZE\n",
    "        self.viewer = rendering.Viewer(screen_width,\n",
    "                                       screen_height)\n",
    "        all_objects = []\n",
    "        ## List of border points' coordinates\n",
    "        bp_list = [\n",
    "            (CELL_SIZE - MARGIN, CELL_SIZE - MARGIN),\n",
    "            (screen_width - CELL_SIZE + MARGIN, CELL_SIZE - MARGIN),\n",
    "            (screen_width - CELL_SIZE + MARGIN,\n",
    "             screen_height - CELL_SIZE + MARGIN),\n",
    "            (CELL_SIZE - MARGIN, screen_height - CELL_SIZE + MARGIN)\n",
    "        ]\n",
    "        border = rendering.PolyLine(bp_list, True)\n",
    "        border.set_linewidth(5)\n",
    "        all_objects.append(border)\n",
    "        ## Vertical lines\n",
    "        for col in range(self.num_cols + 1):\n",
    "            x1, y1 = (col + 1) * CELL_SIZE, CELL_SIZE\n",
    "            x2, y2 = (col + 1) * CELL_SIZE, \\\n",
    "                     (self.num_rows + 1) * CELL_SIZE\n",
    "            line = rendering.PolyLine([(x1, y1), (x2, y2)], False)\n",
    "            all_objects.append(line)\n",
    "            \n",
    "        ## Horizontal lines\n",
    "        for row in range(self.num_rows + 1):\n",
    "            x1, y1 = CELL_SIZE, (row + 1) * CELL_SIZE\n",
    "            x2, y2 = (self.num_cols + 1) * CELL_SIZE, \\\n",
    "                     (row + 1) * CELL_SIZE\n",
    "            line = rendering.PolyLine([(x1, y1), (x2, y2)], False)\n",
    "            all_objects.append(line)\n",
    "            \n",
    "        ## Traps: --> circles\n",
    "        for cell in trap_cells:\n",
    "            trap_coords = get_coords(*cell, loc='center')\n",
    "            all_objects.append(draw_object([trap_coords]))\n",
    "            \n",
    "        ## Gold: --> triangle\n",
    "        gold_coords = get_coords(*gold_cell,\n",
    "                                 loc='interior_triangle')\n",
    "        all_objects.append(draw_object(gold_coords))\n",
    "        \n",
    "        ## Agent --> square or robot\n",
    "        if (os.path.exists('robot-coordinates.pkl') and CELL_SIZE == 100):\n",
    "            agent_coords = pickle.load(\n",
    "                open('robot-coordinates.pkl', 'rb'))\n",
    "            starting_coords = get_coords(0, 0, loc='center')\n",
    "            agent_coords += np.array(starting_coords)\n",
    "        else:\n",
    "            agent_coords = get_coords(\n",
    "                0, 0, loc='interior_corners')\n",
    "            \n",
    "        agent = draw_object(agent_coords)\n",
    "        self.agent_trans = rendering.Transform()\n",
    "        agent.add_attr(self.agent_trans)\n",
    "        all_objects.append(agent)\n",
    "        for obj in all_objects:\n",
    "            self.viewer.add_geom(obj)\n",
    "            \n",
    "    def render(self, mode='human', done=False):\n",
    "        if done:\n",
    "            sleep_time = 1\n",
    "        else:\n",
    "            sleep_time = self.delay\n",
    "        x_coord = self.s % self.num_cols\n",
    "        y_coord = self.s // self.num_cols\n",
    "        x_coord = (x_coord + 0) * CELL_SIZE\n",
    "        y_coord = (y_coord + 0) * CELL_SIZE\n",
    "        self.agent_trans.set_translation(x_coord, y_coord)\n",
    "        rend = self.viewer.render(return_rgb_array = (mode=='rgb_array'))\n",
    "        time.sleep(sleep_time)\n",
    "        return rend\n",
    "    \n",
    "    def close(self):\n",
    "        if self.viewer:\n",
    "            self.viewer.close()\n",
    "            self.viewer = None\n",
    "            \n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    env = GridWorldENV(5, 6)\n",
    "    for i in range(1):\n",
    "        s = env.reset()\n",
    "        env.render(mode='human', done=False)\n",
    "        while True:\n",
    "            action = np.random.choice(env.nA)\n",
    "            res = env.step(action)\n",
    "            print('Action  ', env.s, action, ' -> ', res)\n",
    "            env.render(mode='human', done=res[2])\n",
    "            if res[2]:\n",
    "                break\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8676f842-04a4-4c66-825e-7c41b8408296",
   "metadata": {},
   "source": [
    "# Solving the grid world problem with Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2c93261-1422-4c5f-aff1-86a4f5151056",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Script: agent.py\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(\n",
    "            self, env,\n",
    "            learning_rate=0.01,\n",
    "            discount_factor=0.9,\n",
    "            epsilon_greedy=0.9,\n",
    "            epsilon_min=0.1,\n",
    "            epsilon_decay=0.95):\n",
    "        self.env = env\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = discount_factor\n",
    "        self.epsilon = epsilon_greedy\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        ## Define the q_table\n",
    "        self.q_table = defaultdict(lambda: np.zeros(self.env.nA))\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            action = np.random.choice(self.env.nA)\n",
    "        else:\n",
    "            q_vals = self.q_table[state]\n",
    "            perm_actions = np.random.permutation(self.env.nA)\n",
    "            q_vals = [q_vals[a] for a in perm_actions]\n",
    "            perm_q_argmax = np.argmax(q_vals)\n",
    "            action = perm_actions[perm_q_argmax]\n",
    "        return action\n",
    "    \n",
    "    def _learn(self, transition):\n",
    "        s, a, r, next_s, done = transition\n",
    "        q_val = self.q_table[s][a]\n",
    "        if done:\n",
    "            q_target = r\n",
    "        else:\n",
    "            q_target = r + self.gamma * np.max(self.q_table[next_s])\n",
    "        ## Update the q_table\n",
    "        self.q_table[s][a] += self.lr * (q_target - q_val)\n",
    "        ## Adjust the epsilon\n",
    "        self._adjust_epsilon()\n",
    "        \n",
    "    def _adjust_epsilon(self):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e0d764ee-c670-41bd-a698-4d19301424ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Script: qlearning.py\n",
    "\n",
    "# from gridworld_env import GridWorldENV\n",
    "# from agent import Agent\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "Transition = namedtuple(\n",
    "    'Transition', ('state', 'action', 'reward',\n",
    "                   'next_state', 'done'))\n",
    "    \n",
    "    \n",
    "def run_qlearning(agent, env, num_episodes=50):\n",
    "    history = []\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        env.render(mode='human')\n",
    "        final_reward, n_moves = 0.0, 0\n",
    "        while True:\n",
    "            action = agent.choose_action(state)\n",
    "            next_s, reward, done, _ = env.step(action)\n",
    "            agent._learn(Transition(state, actio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d631b9ce-8866-4a3e-a92f-6d5b16cb3f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4980f89b-b56f-4b9f-8d82-e6e7f5b27322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198b4b85-f6c4-4361-9a97-70eee58adb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c87c352-3556-4e4c-8eec-e0bd300167e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e5a409-696d-4fc6-b151-77f340199852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84475bc-ba13-41a4-a93a-a0b7fb90555d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e39e7a-5fa1-44fe-b7f8-5e9714859f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc93bd-db31-4415-ab39-f4b4cd5f9b17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RaschkaMLbook",
   "language": "python",
   "name": "raschkamlbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
