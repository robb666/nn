{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 14 - Classifying Images with Deep Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1d Implementation: [ 5. 14. 16. 26. 24. 34. 19. 22.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def conv1d(x, w, p=0, s=1):\n",
    "    w_rot = np.array(w[::-1])\n",
    "    x_padded = np.array(x)\n",
    "    if p > 0:\n",
    "        zero_pad = np.zeros(shape=p)\n",
    "        x_padded = np.concatenate([\n",
    "            zero_pad, x_padded, zero_pad\n",
    "        ])\n",
    "    res = []\n",
    "    for i in range(0, int((len(x_padded) - len(w_rot))) + 1, s):\n",
    "        res.append(np.sum(x_padded[i:i + w_rot.shape[0]] * w_rot))\n",
    "    return np.array(res)\n",
    "\n",
    "\n",
    "## Testing:\n",
    "x = [1, 3, 2, 4, 5, 6, 1, 3]\n",
    "w = [1, 0, 3, 1, 2]\n",
    "\n",
    "print('Conv1d Implementation:',\n",
    "       conv1d(x, w, p=2, s=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Results: [ 5 14 16 26 24 34 19 22]\n"
     ]
    }
   ],
   "source": [
    "print('NumPy Results:',\n",
    "      np.convolve(x, w, mode='same'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing a discrete convolution in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d Implementation:\n",
      " [[11. 25. 32. 13.]\n",
      " [19. 25. 24. 13.]\n",
      " [13. 28. 25. 17.]\n",
      " [11. 17. 14.  9.]]\n",
      "\n",
      "SciPy Results:\n",
      " [[11 25 32 13]\n",
      " [19 25 24 13]\n",
      " [13 28 25 17]\n",
      " [11 17 14  9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "\n",
    "\n",
    "def conv2d(X, W, p=(0, 0), s=(1, 1)):\n",
    "    W_rot = np.array(W)[::-1, ::-1]\n",
    "    X_orig = np.array(X)\n",
    "    n1 = X_orig.shape[0] + 2*p[0]\n",
    "    n2 = X_orig.shape[1] + 2*p[1]\n",
    "    X_padded = np.zeros(shape=(n1, n2))\n",
    "    X_padded[p[0]: p[0] + X_orig.shape[0],\n",
    "             p[1]: p[1] + X_orig.shape[1]] = X_orig\n",
    "    \n",
    "    res = []\n",
    "    for i in range(0,\n",
    "                   int((X_padded.shape[0] - W_rot.shape[0]) / s[0]) + 1, s[0]):\n",
    "        res.append([])\n",
    "        for j in range(0,\n",
    "                       int((X_padded.shape[1] - W_rot.shape[1]) / s[1]) + 1, s[1]):\n",
    "            X_sub = X_padded[i:i + W_rot.shape[0],\n",
    "                             j:j + W_rot.shape[1]]\n",
    "            res[-1].append(np.sum(X_sub * W_rot))\n",
    "            \n",
    "    return (np.array(res))\n",
    "    \n",
    "    \n",
    "    \n",
    "## Testing:\n",
    "X = [[1, 3, 2, 4], [5, 6, 1, 3], [1, 2, 0, 2], [3, 4, 3, 2]]\n",
    "W = [[1, 0, 3], [1, 2, 1], [0, 1, 1]]\n",
    "\n",
    "\n",
    "print('Conv2d Implementation:\\n',\n",
    "      conv2d(X, W, p=(1, 1), s=(1, 1)))\n",
    "\n",
    "print()\n",
    "\n",
    "print('SciPy Results:\\n',\n",
    "      scipy.signal.convolve2d(X, W, mode='same'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torchvision.io import read_image\n",
    "\n",
    "# img = read_image('example-image.png')\n",
    "\n",
    "# print('Image shape:', img.shape)\n",
    "# print('Number of channels:', img.shape[0])\n",
    "# print('Image data type:', img.dtype)\n",
    "# print(img[:, 100:102, 100:102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss_func = nn.BCELoss()\n",
    "loss = loss_func(torch.tensor([0.9]), torch.tensor([1.0]))\n",
    "l2_lambda = 0.001\n",
    "conv_layer = nn.Conv2d(in_channels=3,\n",
    "                       out_channels=5,\n",
    "                       kernel_size=5)\n",
    "l2_penalty = l2_lambda * sum(\n",
    "        [(p**2).sum() for p in conv_layer.parameters()])\n",
    "\n",
    "loss_with_penalty = loss + l2_penalty\n",
    "linear_layer = nn.Linear(10, 16)\n",
    "\n",
    "l2_penalty = l2_lambda * sum([(p**2).sum() for p in linear_layer.parameters()])\n",
    "loss_with_penalty = loss + l2_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(\n",
    "#     model.parameters(),\n",
    "#     weight_decay=l2_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE (w Probas): 0.3711\n",
      "BCE (w Logits): 0.3711\n"
     ]
    }
   ],
   "source": [
    "####### Binary Cross-entropy\n",
    "\n",
    "logits = torch.tensor([0.8])\n",
    "probas = torch.sigmoid(logits)\n",
    "target = torch.tensor([1.0])\n",
    "bce_loss_fn = nn.BCELoss()\n",
    "bce_logits_loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(f'BCE (w Probas): {bce_loss_fn(probas, target):.4f}')\n",
    "print(f'BCE (w Logits): {bce_logits_loss_fn(logits, target):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCE (w Probas): 0.5996\n",
      "CCE (w Logits): 0.5996\n"
     ]
    }
   ],
   "source": [
    "####### Categorical Cross-entropy\n",
    "\n",
    "logits = torch.tensor([[1.5, 0.8, 2.1]])\n",
    "probas = torch.softmax(logits, dim=1)\n",
    "target = torch.tensor([2])\n",
    "cce_loss_fn = nn.NLLLoss()\n",
    "cce_logits_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f'CCE (w Probas): {cce_logits_loss_fn(logits, target):.4f}')\n",
    "print(f'CCE (w Logits): {cce_loss_fn(torch.log(probas), target):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a deep CNN using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "image_path = './'\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_dataset = torchvision.datasets.MNIST(root=image_path, train=True,\n",
    "                                           transform=transform, download=True)\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "mnist_valid_dataset = Subset(mnist_dataset,\n",
    "                             torch.arange(10000))\n",
    "\n",
    "mnist_train_dataset = Subset(mnist_dataset,\n",
    "                             torch.arange(\n",
    "                                 10000, len(mnist_dataset)\n",
    "                             ))\n",
    "\n",
    "mnist_test_dataset = torchvision.datasets.MNIST(\n",
    "    root=image_path, train=False,\n",
    "    transform=transform, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "train_dl = DataLoader(mnist_train_dataset,\n",
    "                      batch_size,\n",
    "                      shuffle=True)\n",
    "valid_dl = DataLoader(mnist_valid_dataset,\n",
    "                      batch_size,\n",
    "                      shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a CNN using the torch.nn module\n",
    "# Configuring CNN layers in PyTorch\n",
    "# Constructing a CNN in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
